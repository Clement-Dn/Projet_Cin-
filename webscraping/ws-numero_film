import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import time

pages = ["https://www.allocine.fr/films/?page=" + str(num1) for num1 in range(2, 4)]
# ok for page in pages: print(page)

numeros_film = [] # numeros_film est l'array qui stock le numéro des films

for page in pages:
  code_page = requests.get(page)
  soup = BeautifulSoup(code_page.text, 'html.parser')
  meta_title = soup.select('.meta-title > a')
  print(page)
  for link in meta_title:
    href = link.get('href')
    nombre = re.findall(r'\d+', href)
    numeros_film.extend(nombre)

print(numeros_film)

# Créer un DataFrame pandas avec les numéros de films
df = pd.DataFrame(numeros_film, columns=['num_film'])
# Enregistrer le DataFrame dans un fichier CSV
df.to_csv('numeros_film2_4.csv', index=False)


